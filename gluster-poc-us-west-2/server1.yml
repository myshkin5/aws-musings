---
  AWSTemplateFormatVersion: 2010-09-09

  Description: A GlusterFS peer server.

  Parameters:
    NamePrefix:
      Type: String
      Description: The name prefix of the server.
    Domain:
      Type: String
      Description: The domain containing the server. The name plus the domain, separated by a dot, make up the server's
        fully qualified domain name.
    KeyName:
      Type: AWS::EC2::KeyPair::KeyName
      Description: SSH key name used to connect to the server.
    AWSMusingsS3URL:
      Type: String
      Description: S3 path to aws-musings.
    AvailabilityZone:
      Type: String
      Description: The availability zone where the server will be created.
    SubnetId:
      Type: String
      Description: The id of the subnet where the server will be added.
    SecurityGroupId:
      Type: String
      Description: The id of the security group protecting the server.

  Resources:
    Instance1:
      Type: AWS::EC2::Instance
      Metadata:
        "AWS::CloudFormation::Init":
          config:
            files:
              /etc/cfn/cfn-hup.conf:
                source: !Join [ /, [ !Ref AWSMusingsS3URL, common/cfn-hup.conf ] ]
                context:
                  STACK_ID: !Ref "AWS::StackId"
                  REGION: !Ref "AWS::Region"
                mode: 000400
                owner: root
                group: root
              /etc/cfn/hooks.d/cfn-auto-reloader.conf:
                source: !Join [ /, [ !Ref AWSMusingsS3URL, common/cfn-auto-reloader.conf ] ]
                context:
                  STACK_ID: !Ref "AWS::StackId"
                  REGION: !Ref "AWS::Region"
                  INSTANCE_NAME: Instance1

              /etc/dhcp/dhclient.conf:
                source: !Join [ /, [ !Ref AWSMusingsS3URL, common/dhclient.conf ] ]
                context:
                  FQDN: !Join [ "", [ !Ref NamePrefix, 1., !Ref Domain ] ]

              /home/ec2-user/.bashrc:
                source: !Join [ /, [ !Ref AWSMusingsS3URL, common/bashrc.sh ] ]
                mode: 000644
                owner: ec2-user
                group: ec2-user
              /root/.bashrc:
                source: !Join [ /, [ !Ref AWSMusingsS3URL, common/bashrc.sh ] ]
                mode: 000644
                owner: root
                group: root
      Properties:
        DisableApiTermination: false
        ImageId: ami-b5a7ea85
        InstanceType: t2.micro
        KeyName: !Ref KeyName
        Monitoring: false
        Tags:
        - Key: Name
          Value: !Join [ "", [ !Ref NamePrefix, 1 ] ]
        Volumes:
        - { VolumeId: !Ref Volume, Device: /dev/sdb }
        NetworkInterfaces:
        - AssociatePublicIpAddress: false
          DeleteOnTermination: true
          Description: Primary network interface
          DeviceIndex: 0
          SubnetId: !Ref SubnetId
          GroupSet: [ !Ref SecurityGroupId ]
        UserData:
          Fn::Base64:
            !Join [ "", [
              "#!/bin/bash\n",

              "set -e -x\n",

              "export HOSTNAME=", !Ref NamePrefix, "1\n",
              "export STACK_NAME=\"", !Ref "AWS::StackName", "\"\n",
              "export RESOURCE=NATInstance\n",
              "export REGION=\"", !Ref "AWS::Region", "\"\n",
              "export AWS_MUSINGS_S3_URL=\"", !Ref AWSMusingsS3URL, "\"\n",

              "curl --output /tmp/bootstrap.sh --silent $AWS_MUSINGS_S3_URL/common/bootstrap.sh\n",
              "source /tmp/bootstrap.sh\n",
              "aws-bootstrap\n",

              "# Gluster configuration common to both servers\n",
              "echo -e \"n\n\n\n\n\nw\" | fdisk /dev/xvdb || aws-error-exit 'Failed fdisk'\n",
              "mkfs.ext4 /dev/xvdb1 || aws-error-exit 'Failed mkfs'\n",
              "mkdir /mnt/brick1 || aws-error-exit 'Failed mkdir'\n",
              "echo \"/dev/xvdb1 /mnt/brick1 ext4 defaults 1 2\" >> /etc/fstab\n",
              "wget -P /etc/yum.repos.d ",
                "http://download.gluster.org/pub/gluster/glusterfs/LATEST/EPEL.repo/glusterfs-epel.repo ",
                  " || aws-error-exit 'Failed gluster repo wget'\n",
              "sed -i 's/$releasever/6/g' /etc/yum.repos.d/glusterfs-epel.repo\n",
              "yum -y install glusterfs{-fuse,-server}\n",
              "chkconfig glusterd on\n",

              "# Gluster configuration for server1 only\n",
              "gluster peer probe ", !Ref NamePrefix, "2 || aws-error-exit 'gluster peer probe failed'\n",
              "gluster volume create gluster replica 2 transport tcp ",
                !Ref NamePrefix, "1:/mnt/brick1/brick1 ",
                !Ref NamePrefix, "2:/mnt/brick1/brick1 ",
                  "|| aws-error-exit 'gluster volume create failed'\n",

              "# All done so signal success\n",
              "aws-signal-success\n",
              "reboot\n"
            ] ]
      CreationPolicy:
        ResourceSignal:
          Timeout: PT10M

    Volume:
      Type: AWS::EC2::Volume
      Properties:
        AvailabilityZone: !Ref AvailabilityZone
        Size: 10
        VolumeType: gp2
        Tags:
        - Key: Name
          Value: !Join [ "", [ !Ref NamePrefix, 1-volume ] ]
